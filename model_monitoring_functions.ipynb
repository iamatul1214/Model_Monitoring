{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e5c7252",
   "metadata": {},
   "source": [
    "## This notebook contains the functions which can be used to monitor the ml models deployed on production environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ab6498",
   "metadata": {},
   "source": [
    "### In order to monitor the ml models, we will consider two paramters-\n",
    "### 1.PSI (Probability stability index)\n",
    "### 2. Measure of central tendency (Mean, Median and mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f593cd6",
   "metadata": {},
   "source": [
    "## Using PSI/CSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea85b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(score_initial, score_new, num_bins = 10, mode = 'fixed'):\n",
    "    \n",
    "    epsilon = 1e-4\n",
    "    \n",
    "    # Sort the data\n",
    "    score_initial.sort()\n",
    "    score_new.sort()\n",
    "    \n",
    "    # Prepare the bins\n",
    "    min_val = min(min(score_initial), min(score_new))\n",
    "    max_val = max(max(score_initial), max(score_new))\n",
    "    if mode == 'fixed':\n",
    "        bins = [min_val + (max_val - min_val)*(i)/num_bins for i in range(num_bins+1)]\n",
    "    elif mode == 'quantile':\n",
    "        bins = pd.qcut(score_initial, q = num_bins, retbins = True)[1] # Create the quantiles based on the initial population\n",
    "    else:\n",
    "        raise ValueError(f\"Mode \\'{mode}\\' not recognized. Your options are \\'fixed\\' and \\'quantile\\'\")\n",
    "    bins[0] = min_val - epsilon # Correct the lower boundary\n",
    "    bins[-1] = max_val + epsilon # Correct the higher boundary\n",
    "        \n",
    "        \n",
    "    # Bucketize the initial population and count the sample inside each bucket\n",
    "    bins_initial = pd.cut(score_initial, bins = bins, labels = range(1,num_bins+1))\n",
    "    df_initial = pd.DataFrame({'train': score_initial, 'bin': bins_initial})\n",
    "    grp_initial = df_initial.groupby('bin').count()\n",
    "    grp_initial['percent_train'] = grp_initial['train'] / sum(grp_initial['train'])\n",
    "    \n",
    "    # Bucketize the new population and count the sample inside each bucket\n",
    "    bins_new = pd.cut(score_new, bins = bins, labels = range(1,num_bins+1))\n",
    "    df_new = pd.DataFrame({'prod': score_new, 'bin': bins_new})\n",
    "    grp_new = df_new.groupby('bin').count()\n",
    "    grp_new['percent_prod'] = grp_new['prod'] / sum(grp_new['prod'])\n",
    "    \n",
    "    # Compare the bins to calculate PSI\n",
    "    psi_df = grp_initial.join(grp_new, on = \"bin\", how = \"inner\")\n",
    "    \n",
    "    # Add a small value for when the percent is zero\n",
    "    psi_df['percent_train'] = psi_df['percent_train'].apply(lambda x: epsilon if x == 0 else x)\n",
    "    psi_df['percent_prod'] = psi_df['percent_prod'].apply(lambda x: epsilon if x == 0 else x)\n",
    "    \n",
    "    # Calculate the psi\n",
    "    psi_df['psi'] = (psi_df['percent_train'] - psi_df['percent_prod']) * np.log(psi_df['percent_train'] / psi_df['percent_prod'])\n",
    "    \n",
    "    # Return the psi values\n",
    "    # print(psi_df)\n",
    "    return psi_df,psi_df['psi'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e89829f",
   "metadata": {},
   "source": [
    "### Function to plot the bucket wise distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aa3950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "def plot_train_vs_prod(df:pd.DataFrame,train_distribution_col:str,prod_distribution_col:str,title:str)->None:\n",
    "    df[[train_distribution_col,prod_distribution_col]].plot(kind = 'bar')\n",
    "    plot_title = f\"{title} train vs prod\"\n",
    "    plt.title(plot_title)\n",
    "    plt.ylabel(\"score frequency\")\n",
    "    plt.xlabel(\"score buckets\")\n",
    "    plt.rcParams[\"figure.figsize\"] = (15,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c82a0a9",
   "metadata": {},
   "source": [
    "### Function to just calculate PSI when bucketization is already done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559a8e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psi_overall(training_probs,prod_probs):\n",
    "    from math import log\n",
    "    return (sum((training_probs[i]-prod_probs[i])*log(training_probs[i]/prod_probs[i]) for i in range(len(training_probs))))/len(training_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f598a972",
   "metadata": {},
   "source": [
    "### Function to calculate the kl divergence when bucketization is already done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61507e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kl_divergence_overall(trained_scores,prod_scores):\n",
    "    from math import log\n",
    "    return (sum(trained_scores[i] * log(trained_scores[i]/prod_scores[i]) for i in range(len(trained_scores))))/len(trained_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da0b52",
   "metadata": {},
   "source": [
    "## Using the measures of central tendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f24bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_central_tendency(training_values, new_values):\n",
    "    from collections import Counter\n",
    "    ## calculating mean \n",
    "    training_values_mean = float(sum(training_values)/len(training_values))\n",
    "    new_values_mean = float(sum(new_values)/len(new_values))\n",
    "    \n",
    "    ## calculating median\n",
    "    training_values.sort()\n",
    "    new_values.sort()\n",
    "    n = len(training_values)\n",
    "    if n % 2 == 0:\n",
    "        training_values_median = float((training_values[n//2] + training_values[n//2 - 1])/2)\n",
    "    training_values_median = float(training_values[n//2])\n",
    "    n = len(new_values)\n",
    "    if n% 2==0:\n",
    "        new_values_median = float((new_values[n//2]+new_values[n//2 - 1])/2)\n",
    "    new_values_median = float(new_values[n//2])\n",
    "    \n",
    "    ## calculating the mode\n",
    "    freq = Counter(training_values)\n",
    "    training_values_mode = [k for k,v in freq.items() if v == freq.most_common(1)[0][1]]\n",
    "    if len(training_values_mode)==1:\n",
    "        training_values_mode = training_values_mode[0]\n",
    "    freq = Counter(new_values)\n",
    "    new_values_mode = [k for k,v in freq.items() if v == freq.most_common(1)[0][1]]\n",
    "    if len(new_values_mode)==1:\n",
    "        new_values_mode = new_values_mode[0]\n",
    "    \n",
    "    \n",
    "     ## creating dataframe for storing the central trendecies\n",
    "    index = ['mean','median','mode']\n",
    "    train_tendecy = [training_values_mean,training_values_median,training_values_mode]\n",
    "    new_tendency = [new_values_mean,new_values_median,new_values_mode]\n",
    "    \n",
    "    df = pd.DataFrame({'training (initial)':train_tendecy,'Prod (newly observed)':new_tendency}, index=index)\n",
    "    display(df)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
